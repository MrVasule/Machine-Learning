
# Machine Learning 
Macine learning is brach of computer science. ML technique gives computer a ability to learn without being explicity programmed.

## Aim - 
    Minimze the Error or Loss in our data.

## Objective - 
    1- Simple and efficient tools for predictive data analysis.
    2- Accessible to everybody, and reusable in various contexts.
    3- Built on NumPy, SciPy, Seaborn, and matplotlib.
    4- Open source, commercially usable.
    
## Types - 
### a - Supervised Learning
### b - Unsupervised Learning

## a - Supervised Learning -  
Supervised learning is an approach to creating artificial intelligence (AI), where a computer algorithm is trained on input data that has been labeled for a particular output.
## Aim - 
    Predict the correct label for unseen data.
During Traning - SL algorithm searches for pattern that corelate with the desired output.

After  Traning - Take in unseen input and determine which label to classify it to.

## Types - 
  ## Regression 
  ## Classsification 

## Regression - 
Find relationship between dependend and independent variable.
Goal - To predict continues values such as test score.

## Type - 
1 - Linear Regression - 

    A linear regression is linear approximation of cousal relationship betweeen two or more variable.

2 - Multiple Linear Regression - 

    when we have more than one independent variable.

3 - Decision Tree -

    A decision tree is a flowchart-like structure in which each internal node represents a "test" on an attribute.

    Type - Decision Tree Regression & Decision Tree Classifier

4 - Support Vector Machine - 

    SVM finding the best fitting line or best decision boundery which one help us to seprate our space in to classes.
    
    Type - Support Vector Regression & Support Vector Classifier

5 - Polynomial Regression - 

     A form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modelled as an nth degree polynomial in x. 
     For this reason, polynomial regression is considered to be a special case of multiple linear regression.

6 - Logistic Regression - 

    It is a regression which is used for classification problem's.
    Logistic Regression that a possible outcome are not numerical but rather categrical.

7 - Random Forest -

    Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time.

8 -  K Nearest Neighbour - 

    Find the Quary point in two categaries.

## L1 and L2 - 
    - L1(lasso),L2(Ridge) both are extension of Linear Regression.
    - The Diffrence between them penalty term.
    - 'Ridge' use squared penalty and 'lasso' use absolute value of penalty.

## Dimension Reduction - 
    Process of reducing the dimension of your features set.
- Features Elimination 
- Features Extraction (PCA)

## Classification - 
    - Input assign class and categaries.
    - Mapping function used to classify unseen data.

## Type -
1 - Decision Tree Classification

2 - Support Vector Machine Classification

3 - Random Forest Classification

4 - Navie Bayes -

    Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem.
    The “naive” assumption of conditional independence between every pair of features given the value of the class variable.

## b - Unsupervised Learning - 
Unsupervised learning allows the system to identify patterns within data sets on its own.

## Aim -

    Analysis data and find important understanding pattern.

- Does not labelled data, rather relise on the data features.
- Used exploricity data analysis.

## Type - 
## Clustering - 
     Process to group in data into diffrent cluster or group.
- Partition Based Clustering -
Each data point to belong a single cluster.
    
    a - K-means  

    b - Mean Shift 
- Hierarchical Based Clustering - 
cluster with in clusters. Data point may belong to many cluster.

    a - AngloMerative (Bottom up)

    b - Division (bottom Down)
- Density Based Clustering - 
 Finds core samples of high density and expands clusters from them.

    a - DBSCAN - Density Based Spatial Clustering of Applications with Noise

# Refrence - 
- Google.com
- en.wikipedia.org
- scikit-learn.org
- freeCodeCamp.org



   
